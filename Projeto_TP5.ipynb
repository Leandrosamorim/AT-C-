{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leandrosamorim/AT-C-/blob/master/Projeto_TP5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalação do Spark"
      ],
      "metadata": {
        "id": "YXtYVZ2a55MB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBcWjhOZbfaL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2795f09e-97d3-441e-9ec4-daea00d9eac3"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!apt-get install unzip\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.4.0/spark-3.4.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.4.0-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version\n",
        "\n",
        "\n",
        "import pyspark\n",
        "import random\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Spark_SQL\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"Initialization successful\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-26ubuntu3.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285387 sha256=92f491189f8de49946f8343fa3665fe84a858f6cf5501de31b46c5a29e49a2e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n",
            "openjdk version \"1.8.0_382\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_382-8u382-ga-1~22.04.1-b05)\n",
            "OpenJDK 64-Bit Server VM (build 25.382-b05, mixed mode)\n",
            "Initialization successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verificar o status da seção iniciada"
      ],
      "metadata": {
        "id": "QC2MUVcQTYpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Executando apenas a variável sc em uma célula veremos algumas informações sobre a sessão Spark criada.\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "A2tcg6uITYBX",
        "outputId": "338c0f0f-c103-4b1e-8bff-5d71094d5bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7ab21ecedfc0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://3e1ea57520ac:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark_SQL</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importar um dado externo"
      ],
      "metadata": {
        "id": "iJqtZPzUTzUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!wget --quiet --show-progress https://filebin.net/eo8odp08q6njajlk/books.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hWfyCNWTtbX",
        "outputId": "bdd44c01-c1ea-426f-d746-3c6df402a8a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "books.zip           100%[===================>]   1.63M  1.50MB/s    in 1.1s    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -d ./datasets ./books.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3PrDT5iGY3J",
        "outputId": "2ce75f8c-5093-47eb-91f2-09a294befc4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ./books.zip\n",
            "  inflating: ./datasets/gutenberg.org_cache_epub_11861_pg11861.txt  \n",
            "  inflating: ./datasets/gutenberg.org_cache_epub_24625_pg24625.txt  \n",
            "  inflating: ./datasets/gutenberg.org_cache_epub_26777_pg26777.txt  \n",
            "  inflating: ./datasets/gutenberg.org_cache_epub_29484_pg29484.txt  \n",
            "  inflating: ./datasets/gutenberg.org_cache_epub_29666_pg29666.txt  \n",
            "  inflating: ./datasets/gutenberg.org_cache_epub_38677_pg38677.txt  \n",
            "  inflating: ./datasets/gutenberg.org_cache_epub_39006_pg39006.txt  \n",
            "  inflating: ./datasets/gutenberg.org_cache_epub_44540_pg44540.txt  \n",
            "  inflating: ./datasets/gutenberg.org_files_56949_56949-0.txt  \n",
            "  inflating: ./datasets/gutenberg.org_files_63606_63606-0.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files = os.listdir(\"./datasets\")\n",
        "files = [f for f in files if os.path.isfile(\"./datasets\"+'/'+f)]\n",
        "print(*files, sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgQcRKtNGdMB",
        "outputId": "09691c35-9b80-4fea-e09f-f3153e6f5f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gutenberg.org_cache_epub_29484_pg29484.txt\n",
            "gutenberg.org_cache_epub_26777_pg26777.txt\n",
            "gutenberg.org_cache_epub_38677_pg38677.txt\n",
            "gutenberg.org_files_63606_63606-0.txt\n",
            "gutenberg.org_cache_epub_29666_pg29666.txt\n",
            "gutenberg.org_cache_epub_11861_pg11861.txt\n",
            "gutenberg.org_cache_epub_44540_pg44540.txt\n",
            "gutenberg.org_files_56949_56949-0.txt\n",
            "gutenberg.org_cache_epub_39006_pg39006.txt\n",
            "gutenberg.org_cache_epub_24625_pg24625.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregar o dado em um dataframe"
      ],
      "metadata": {
        "id": "dxlJMXXpT_qS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = {}\n",
        "for file in files:\n",
        "  dfs[file[:-4]] = spark.read.text(f\"./datasets/{file}\")"
      ],
      "metadata": {
        "id": "P9OpzkhnT4xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Verificando o tipo de objeto criado\n",
        "type(dfs['gutenberg.org_cache_epub_26777_pg26777'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPW0gWyMUMfo",
        "outputId": "3fd90d5c-05f4-4758-9b6a-18158f294389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Espiando o dataset\n",
        "dfs['gutenberg.org_cache_epub_29484_pg29484'].show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRSKw2MFUQc1",
        "outputId": "9b22ca22-16c2-4e0c-c41a-e924242b4cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|               value|\n",
            "+--------------------+\n",
            "|The Project Guten...|\n",
            "|                    |\n",
            "|This ebook is for...|\n",
            "|most other parts ...|\n",
            "|whatsoever. You m...|\n",
            "|of the Project Gu...|\n",
            "|at www.gutenberg....|\n",
            "|you will have to ...|\n",
            "|before using this...|\n",
            "|                    |\n",
            "|Title: A Revoluçã...|\n",
            "|                    |\n",
            "|                    |\n",
            "|Author: Francisco...|\n",
            "|                    |\n",
            "|Release date: Jul...|\n",
            "|                    |\n",
            "|Language: Portuguese|\n",
            "|                    |\n",
            "|Original publicat...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfs['gutenberg.org_cache_epub_29484_pg29484'].createOrReplaceTempView(\"book1\")\n",
        "dfs['gutenberg.org_cache_epub_26777_pg26777'].createOrReplaceTempView(\"book2\")\n",
        "dfs['gutenberg.org_cache_epub_38677_pg38677'].createOrReplaceTempView(\"book3\")\n",
        "dfs['gutenberg.org_files_63606_63606-0'].createOrReplaceTempView(\"book4\")\n",
        "dfs['gutenberg.org_cache_epub_29666_pg29666'].createOrReplaceTempView(\"book5\")\n",
        "dfs['gutenberg.org_cache_epub_11861_pg11861'].createOrReplaceTempView(\"book6\")\n",
        "dfs['gutenberg.org_cache_epub_44540_pg44540'].createOrReplaceTempView(\"book7\")\n",
        "dfs['gutenberg.org_files_56949_56949-0'].createOrReplaceTempView(\"book8\")\n",
        "dfs['gutenberg.org_cache_epub_39006_pg39006'].createOrReplaceTempView(\"book9\")\n",
        "dfs['gutenberg.org_cache_epub_24625_pg24625'].createOrReplaceTempView(\"book10\")\n"
      ],
      "metadata": {
        "id": "_ruJPOADID-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### REMOVENDO CARACTERES DESCARTAVEIS\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "undesiredChars = \"[^a-zA-Z0-9\\\\s]+\"\n",
        "\n",
        "dfs['gutenberg.org_cache_epub_29484_pg29484'].withColumn(\"cleaned_text\", regexp_replace(\"value\", undesiredChars, \"\")).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cniYlG93hTXx",
        "outputId": "0bd25f58-fffc-4d97-db92-2ee6b3dd3dcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+\n",
            "|               value|        cleaned_text|\n",
            "+--------------------+--------------------+\n",
            "|The Project Guten...|The Project Guten...|\n",
            "|                    |                    |\n",
            "|This ebook is for...|This ebook is for...|\n",
            "|most other parts ...|most other parts ...|\n",
            "|whatsoever. You m...|whatsoever You ma...|\n",
            "|of the Project Gu...|of the Project Gu...|\n",
            "|at www.gutenberg....|at wwwgutenbergor...|\n",
            "|you will have to ...|you will have to ...|\n",
            "|before using this...|before using this...|\n",
            "|                    |                    |\n",
            "|Title: A Revoluçã...|Title A Revoluo P...|\n",
            "|                    |                    |\n",
            "|                    |                    |\n",
            "|Author: Francisco...|Author Francisco ...|\n",
            "|                    |                    |\n",
            "|Release date: Jul...|Release date July...|\n",
            "|                    |                    |\n",
            "|Language: Portuguese| Language Portuguese|\n",
            "|                    |                    |\n",
            "|Original publicat...|Original publicat...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### REMOVENDO LINHAS DESCARTAVEIS\n",
        "dfs['gutenberg.org_cache_epub_29484_pg29484'].filter(dfs['gutenberg.org_cache_epub_29484_pg29484'][\"value\"] != \"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QALXheMifZ56",
        "outputId": "10838900-c61b-4b04-8708-eecb7068d4c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|               value|\n",
            "+--------------------+\n",
            "|The Project Guten...|\n",
            "|                    |\n",
            "|This ebook is for...|\n",
            "|most other parts ...|\n",
            "|whatsoever. You m...|\n",
            "|of the Project Gu...|\n",
            "|at www.gutenberg....|\n",
            "|you will have to ...|\n",
            "|before using this...|\n",
            "|Title: A Revoluçã...|\n",
            "|Author: Francisco...|\n",
            "|Release date: Jul...|\n",
            "|Language: Portuguese|\n",
            "|Original publicat...|\n",
            "|Credits: Produced...|\n",
            "|*** START OF THE ...|\n",
            "|Produced by Pedro...|\n",
            "|Proofreading Team...|\n",
            "|                 ...|\n",
            "|                 ...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### REMOVENDO STOPWORDSf\n",
        "from pyspark.ml.feature import StopWordsRemover\n",
        "remover = StopWordsRemover(inputCol=\"value\", outputCol=\"filtered\")\n",
        "remover.transform(dfs['gutenberg.org_cache_epub_26777_pg26777']).head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "vcT8j0kdol70",
        "outputId": "7893b021-42b9-4422-bce7-4cdd3a9afc0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IllegalArgumentException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-657ffad13868>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStopWordsRemover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mremover\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStopWordsRemover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"filtered\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mremover\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gutenberg.org_cache_epub_26777_pg26777'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: Input type must be array<string> but got string."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### LEMATIZAÇÃO\n",
        "import nltk\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "nltk.download(\"wordnet\")\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    words = text.split()\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return ' '.join(lemmatized_words)\n",
        "\n",
        "lemmatize_udf = udf(lemmatize_text, StringType())\n",
        "\n",
        "lemmatized = dfs['gutenberg.org_cache_epub_26777_pg26777'].withColumn(\"lemmatized_text\", lemmatize_udf(dfs['gutenberg.org_cache_epub_26777_pg26777'][\"value\"]))\n",
        "lemmatized.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjc_WnzfstUY",
        "outputId": "0302ee5c-52cf-46ca-ed80-8dd2e208e4af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+\n",
            "|               value|     lemmatized_text|\n",
            "+--------------------+--------------------+\n",
            "|The Project Guten...|The Project Guten...|\n",
            "|                    |                    |\n",
            "|This ebook is for...|This ebook is for...|\n",
            "|most other parts ...|most other part o...|\n",
            "|whatsoever. You m...|whatsoever. You m...|\n",
            "|of the Project Gu...|of the Project Gu...|\n",
            "|at www.gutenberg....|at www.gutenberg....|\n",
            "|you will have to ...|you will have to ...|\n",
            "|before using this...|before using this...|\n",
            "|                    |                    |\n",
            "|Title: A Revoluçã...|Title: A Revoluçã...|\n",
            "|                    |                    |\n",
            "|                    |                    |\n",
            "|Author: Francisco...|Author: Francisco...|\n",
            "|                    |                    |\n",
            "|Release date: Oct...|Release date: Oct...|\n",
            "|                M...|Most recently upd...|\n",
            "|                    |                    |\n",
            "|Language: Portuguese|Language: Portuguese|\n",
            "|                    |                    |\n",
            "+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}